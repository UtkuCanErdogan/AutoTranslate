{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Tr-Eng.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1lOoAC-zR7-BNIcd_iFQcvYRyFhcbKMXl","authorship_tag":"ABX9TyMY9SP8sect+hbbZpnRGZl0"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-IBYP-qmwxxO"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNonKmmlXk_S","executionInfo":{"status":"ok","timestamp":1622975443404,"user_tz":-180,"elapsed":43727,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"dbb72da9-d1a8-4248-916c-3dd26f1fb529"},"source":["\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 160772 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"da5WF3IvX7MO"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.python.keras.models import Model\n","from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding,LSTM\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.python.keras.callbacks import ModelCheckpoint\n","from tensorflow.python.keras.preprocessing.text import Tokenizer\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.optimizers import Adam\n","import wave\n","import contextlib\n","import os\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fk-eKwzjX7T0","executionInfo":{"status":"ok","timestamp":1622983389037,"user_tz":-180,"elapsed":7,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"e9f0d826-983b-4d5c-b9fa-93054f64ce98"},"source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","tf.executing_eagerly()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"5qiwfhhXYC7H"},"source":["\n","mark_start = 'ssss '\n","mark_end = ' eeee'\n","\n","data_src = []\n","data_dest = []\n","veri_src = []\n","veri_dest = []\n","\n","for line in open('/content/drive/MyDrive/Python/tur.txt', encoding='UTF-8'):\n","    en_text, tr_text = line.rstrip().split('\\t')\n","    \n","    tr_text = mark_start + tr_text + mark_end\n","    \n","    data_src.append(en_text)\n","    data_dest.append(tr_text)\n","\n","    \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D34emZNNYC93"},"source":["class TokenizerWrap(Tokenizer):\n","    def __init__(self, texts, padding, reverse=False, num_words=None):\n","        Tokenizer.__init__(self, num_words=num_words)\n","        self.fit_on_texts(texts)\n","        self.index_to_word = dict(zip(self.word_index.values(), self.word_index.keys()))\n","        self.tokens = self.texts_to_sequences(texts)\n","        \n","        if reverse:\n","            self.tokens = [list(reversed(x)) for x in self.tokens]\n","            truncating = 'pre'\n","        else:\n","            truncating = 'post'\n","        \n","        self.num_tokens = [len(x) for x in self.tokens]\n","        self.max_tokens = np.mean(self.num_tokens) + np.std(self.num_tokens)*2\n","        self.max_tokens = int(self.max_tokens)\n","        \n","        self.tokens_pad = pad_sequences(self.tokens,\n","                                            maxlen=self.max_tokens,\n","                                            padding=padding,\n","                                            truncating=truncating)\n","    def token_to_word(self, token):\n","        word = ' ' if token==0 else self.index_to_word[token]\n","        return word\n","    def tokens_to_string(self, tokens):\n","        words = [self.index_to_word[token] for token in tokens if token != 0]\n","        text = ' '.join(words)\n","        return text\n","    def text_to_tokens(self, text, padding, reverse=False):\n","        tokens = self.texts_to_sequences([text])\n","        tokens = np.array(tokens)\n","        \n","        if reverse:\n","            tokens = np.flip(tokens, axis=1)\n","            truncating = 'pre'\n","        else:\n","            truncating = 'post'\n","        \n","        tokens = pad_sequences(tokens,\n","                               maxlen=self.max_tokens,\n","                               padding=padding,\n","                               truncating=truncating)\n","        return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEqRks1tYDAT"},"source":["tokenizer_src = TokenizerWrap(texts = data_src,\n","                              padding = 'pre',\n","                              reverse = True,\n","                              num_words = None)\n","tokenizer_dest = TokenizerWrap(texts = data_dest,\n","                              padding = 'post',\n","                              reverse = False,\n","                              num_words = None)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5D6eQ7q_YDC0"},"source":["tokens_src = tokenizer_src.tokens_pad\n","tokens_dest = tokenizer_dest.tokens_pad\n","\n","token_start = tokenizer_dest.word_index[mark_start.strip()]\n","token_end = tokenizer_dest.word_index[mark_end.strip()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cncfhoG_YDFU"},"source":["encoder_input_data = tokens_src\n","decoder_input_data = tokens_dest[:,:-1]\n","decoder_output_data = tokens_dest[:,1:]\n","\n","num_encoder_words = len(tokenizer_src.word_index)+1\n","num_decoder_words = len(tokenizer_dest.word_index)+1\n","\n","\n","\n","embedding_size = 100\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pw5VRGZHYDH0"},"source":["word2vec = {}\n","with open('/content/drive/MyDrive/Colab Notebooks/glove.6B.100d.txt', encoding = 'UTF-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        vec = np.asarray(values[1:], dtype='float32')\n","        word2vec[word] = vec\n","\n","embedding_matrix = np.random.uniform(-1, 1, (num_encoder_words, embedding_size))\n","for word, i in tokenizer_src.word_index.items():\n","    if i < num_encoder_words:\n","        embedding_vector = word2vec.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sStsPi8YDKW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622983436033,"user_tz":-180,"elapsed":19,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"493c744c-2edf-49e2-c408-0bbe114d6c72"},"source":["encoder_input = Input(shape=(None,), name='encoder_input')\n","\n","encoder_embedding = Embedding(input_dim=num_encoder_words,\n","                              output_dim=embedding_size,\n","                              weights=[embedding_matrix],\n","                              trainable=True,\n","                              name='encoder_embedding')\n","state_size = 256\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/initializers_v1.py:67: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iThGuVPHYDMv"},"source":["encoder_gru1 = GRU(state_size, name='encoder_gru1', return_sequences=True)\n","encoder_gru2 = GRU(state_size, name='encoder_gru2', return_sequences=True)\n","encoder_gru3 = GRU(state_size, name='encoder_gru3', return_sequences=False)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TviZTQxdYDPA"},"source":["def connect_encoder():\n","    net = encoder_input\n","    \n","    net = encoder_embedding(net)\n","    \n","    net = encoder_gru1(net)\n","    net = encoder_gru2(net)\n","    net = encoder_gru3(net)\n","    \n","    encoder_output = net\n","    \n","    return encoder_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vi14VejFX7Z3"},"source":["encoder_output = connect_encoder()\n","\n","decoder_initial_state = Input(shape=(state_size,), name='decoder_initial_state')\n","decoder_input = Input(shape=(None,), name='decoder_input')\n","\n","\n","decoder_embedding = Embedding(input_dim = num_decoder_words,\n","                              output_dim = embedding_size,\n","                              name = 'decoder_embedding')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slW9A8rFX7d3"},"source":["decoder_gru1 = GRU(state_size, name='decoder_gru1', return_sequences=True)\n","decoder_gru2 = GRU(state_size, name='decoder_gru2', return_sequences=True)\n","decoder_gru3 = GRU(state_size, name='decoder_gru3', return_sequences=True)\n","\n","\n","decoder_dense = Dense(num_decoder_words,\n","                      activation='linear',\n","                      name='decoder_output')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWN81pxwX7gm"},"source":["def connect_decoder(initial_state):\n","    net = decoder_input\n","    \n","    net = decoder_embedding(net)\n","    \n","    net = decoder_gru1(net,initial_state=initial_state)\n","    net = decoder_gru2(net,initial_state=initial_state)\n","    net = decoder_gru3(net,initial_state=initial_state)\n","\n","    \n","    decoder_output = decoder_dense(net)\n","    \n","    return decoder_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnKWgAsKaPHf"},"source":["decoder_output = connect_decoder(initial_state = encoder_output)\n","model_train = Model(inputs=[encoder_input, decoder_input], outputs =[decoder_output])\n","model_encoder = Model(inputs=[encoder_input], outputs=[encoder_output])\n","decoder_output1 = connect_decoder(initial_state = decoder_initial_state)\n","model_decoder = Model(inputs=[decoder_input, decoder_initial_state], outputs=[decoder_output1])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUI2n20LaPKH"},"source":["def sparse_cross_entropy(y_true, y_pred):\n","    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n","    loss_mean = tf.reduce_mean(loss)\n","    return loss_mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slCQ1UQlaPM8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622983442912,"user_tz":-180,"elapsed":7,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"7ba448eb-4d4d-4098-eb8b-7d01e506abb8"},"source":["optimizer = RMSprop(lr= 1e-3)\n","decoder_target = tf.placeholder(dtype='int32', shape=(None,None))\n","model_train.compile(optimizer=optimizer,\n","                    loss = sparse_cross_entropy,\n","                    target_tensors =[decoder_target] )\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"v5oUbPUDaPPh"},"source":["x_data = {'encoder_input': encoder_input_data, 'decoder_input': decoder_input_data}\n","y_data = {'decoder_output': decoder_output_data}\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MgnUfFRIl_4L"},"source":["path_checkpoint = '/content/drive/MyDrive/Colab Notebooks/Mycheckpoint.keras'\n","checkpoint = ModelCheckpoint(filepath=path_checkpoint, save_weights_only=True)\n","try:\n","    model_train.load_weights(path_checkpoint)\n","except Exception as error:\n","    print('Checkpoint yüklenirken hata oluştu. Eğitime sıfırdan başlanıyor.')\n","    print(error)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqX42RjbaPRM","executionInfo":{"status":"ok","timestamp":1622983451247,"user_tz":-180,"elapsed":4289,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"4d9905ad-5d42-4cfa-9511-a8096e60cf36"},"source":["model_train.fit(x=x_data,\n","                y=y_data,\n","                batch_size=1024,\n","                callbacks = [checkpoint],\n","                epochs=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 473035 samples\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa87b6ab610>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"kwpRDmZ8DmW0"},"source":["mark_start = 'ssss '\n","mark_end = ' eeee'\n","\n","veri_src = []\n","veri_dest = []\n","\n","for line in open('/content/drive/MyDrive/Python/tur.txt', encoding='UTF-8'):\n","    en_metin, tr_metin = line.rstrip().split('\\t')\n","    \n","    en_metin = mark_start + en_metin + mark_end\n","    \n","    veri_src.append(tr_metin)\n","    veri_dest.append(en_metin)\n","\n","src_tokenizer = TokenizerWrap(texts = veri_src,\n","                              padding = 'pre',\n","                              reverse = True,\n","                              num_words = None)\n","dest_tokenizer = TokenizerWrap(texts = veri_dest,\n","                              padding = 'post',\n","                              reverse = False,\n","                              num_words = None)\n","\n","src_tokens = src_tokenizer.tokens_pad\n","dest_tokens = dest_tokenizer.tokens_pad\n","\n","token_basla = dest_tokenizer.word_index[mark_start.strip()]\n","token_bitis = dest_tokenizer.word_index[mark_end.strip()]\n","\n","encoder_input_veri = src_tokens\n","decoder_input_veri = dest_tokens[:,:-1]\n","decoder_output_veri = dest_tokens[:,1:]\n","\n","num_encoder_word = len(tokenizer_src.word_index)+1\n","num_decoder_word = len(tokenizer_dest.word_index)+1\n","\n","\n","\n","embedding_size = 100\n","\n","encoder_giris = Input(shape=(None,), name='encoder_giris')\n","\n","encoderEmbedding = Embedding(input_dim = num_encoder_word,\n","                              output_dim = embedding_size,\n","                              name = 'encoderEmbedding')\n","\n","state_size = 256\n","\n","encoderGRU1 = GRU(state_size, name='encoderGRU1', return_sequences=True)\n","encoderGRU2 = GRU(state_size, name='encoderGRU2', return_sequences=True)\n","encoderGRU3 = GRU(state_size, name='encoderGRU3', return_sequences=False)\n","\n","\n","def connec_encoder():\n","    net = encoder_giris\n","    \n","    net = encoderEmbedding(net)\n","    \n","    net = encoderGRU1(net)\n","    net = encoderGRU2(net)\n","    net = encoderGRU3(net)\n","    \n","    encoder_cikis = net\n","    \n","    return encoder_cikis\n","\n","encoder_cikis = connec_encoder()\n","\n","decoder_initial_stat = Input(shape=(state_size,), name='decoder_initial_stat')\n","decoder_giris = Input(shape=(None,), name='decoder_giris')\n","\n","\n","decoderEmbedding = Embedding(input_dim = num_decoder_word,\n","                              output_dim = embedding_size,\n","                              name = 'decoderEmbedding')\n","    \n","\n","\n","\n","decoderGRU1 = GRU(state_size, name='decoderGRU1', return_sequences=True)\n","decoderGRU2 = GRU(state_size, name='decoderGRU2', return_sequences=True)\n","decoderGRU3 = GRU(state_size, name='decoderGRU3', return_sequences=True)\n","\n","\n","decoderDense = Dense(num_decoder_word,\n","                      activation='linear',\n","                      name='decoder_cikis')\n","\n","def connec_decoder(initial_state):\n","    net = decoder_giris\n","    \n","    net = decoderEmbedding(net)\n","    \n","    net = decoderGRU1(net,initial_state=initial_state)\n","    net = decoderGRU2(net,initial_state=initial_state)\n","    net = decoderGRU3(net,initial_state=initial_state)\n","\n","    \n","    decoder_cikis = decoderDense(net)\n","    \n","    return decoder_cikis\n","\n","decoder_cikis = connec_decoder(initial_state = encoder_cikis)\n","tr_model_train = Model(inputs=[encoder_giris, decoder_giris], outputs =[decoder_cikis])\n","modelEncoder = Model(inputs=[encoder_giris], outputs=[encoder_cikis])\n","decoder_output_1 = connec_decoder(initial_state = decoder_initial_stat)\n","tr_model_decoder = Model(inputs=[decoder_giris, decoder_initial_stat], outputs=[decoder_output_1])\n","\n","tr_model_train.compile(optimizer=optimizer,\n","                    loss = sparse_cross_entropy,\n","                    target_tensors =[decoder_target] )\n","\n","xx_data = {'encoder_giris': encoder_input_veri, 'decoder_giris': decoder_input_veri}\n","yy_data = {'decoder_cikis': decoder_output_veri}\n","\n","path_checkpoint = '/content/drive/MyDrive/Colab Notebooks/TrMycheckpoint.keras'\n","tr_checkpoint = ModelCheckpoint(filepath=path_checkpoint, save_weights_only=True)\n","try:\n","    tr_model_train.load_weights(path_checkpoint)\n","except Exception as error:\n","    print('Checkpoint yüklenirken hata oluştu. Eğitime sıfırdan başlanıyor.')\n","    print(error)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylOIljwwFLh1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622983490471,"user_tz":-180,"elapsed":3439,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"44dfbd29-4438-43f4-f310-be4d96342a8a"},"source":["tr_model_train.fit(x=xx_data,\n","                  y=yy_data,\n","                  batch_size = 1280,\n","                  callbacks = [tr_checkpoint],\n","                  epochs = 0\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 473035 samples\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa868cf8c10>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"PG9rVv9XaPSt"},"source":["def translate(input_text, true_output_text=None):\n","    input_tokens = tokenizer_src.text_to_tokens(text=input_text,\n","                                               reverse=True,\n","                                                padding='pre')\n","    initial_state = model_encoder.predict(input_tokens)\n","    max_tokens = tokenizer_dest.max_tokens\n","    decoder_input_data = np.zeros(shape=(1, max_tokens), dtype=np.int)\n","    token_int = token_start\n","    output_text = ''\n","    count_tokens = 0\n","    \n","    while token_int != token_end and count_tokens < max_tokens:\n","        decoder_input_data[0, count_tokens] = token_int\n","        x_data = {'decoder_initial_state': initial_state, 'decoder_input': decoder_input_data}\n","            \n","        decoder_output = model_decoder.predict(x_data)\n","        token_onehot = decoder_output[0, count_tokens, :]\n","        token_int = np.argmax(token_onehot)\n","            \n","        sampled_word = tokenizer_dest.token_to_word(token_int)\n","        output_text += ' ' + sampled_word\n","        count_tokens += 1\n","        \n","\n","        \n","\n","    return output_text\n","\n","        \n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VzgULj_KH_Ts"},"source":["def tr_translate(input_text):\n","  input_tokens = src_tokenizer.text_to_tokens(text=input_text,\n","                                               reverse=True,\n","                                                padding='pre')\n","  initialState = modelEncoder.predict(input_tokens)\n","  max_tokens = dest_tokenizer.max_tokens\n","  decoder_input_data = np.zeros(shape=(1, max_tokens), dtype=np.int)\n","  token_int = token_basla\n","  metin = ''\n","  count_tokens = 0\n","\n","  while token_int != token_bitis and count_tokens < max_tokens:\n","    decoder_input_veri[0, count_tokens] = token_int\n","    xx_data = {'decoder_initial_stat': initialState, 'decoder_giris' : decoder_input_data}\n","\n","    decoder_cikis = tr_model_decoder.predict(xx_data)\n","    token_onehot = decoder_cikis[0, count_tokens, :]\n","    token_int = np.argmax(token_onehot)\n","\n","    sampled_word = dest_tokenizer.token_to_word(token_int)\n","    metin += ' ' + sampled_word\n","    count_tokens += 1\n","\n","    return metin\n","\n","\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9w3msAVO2r3","executionInfo":{"status":"ok","timestamp":1622983498466,"user_tz":-180,"elapsed":8009,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"ffe72dd3-0e6f-4ac6-bfb6-62aea619a952"},"source":["pip install SpeechRecognition"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting SpeechRecognition\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n","\u001b[K     |████████████████████████████████| 32.8MB 89kB/s \n","\u001b[?25hInstalling collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.8.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pajzYWc2-jk","executionInfo":{"status":"ok","timestamp":1622983501608,"user_tz":-180,"elapsed":3145,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"54c14418-25f3-4e53-8ced-084cca7c0214"},"source":["pip install pydub"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pydub\n","  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W8b3jCBeaPXA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622983697729,"user_tz":-180,"elapsed":174112,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"4ca216b4-9571-4375-a77b-232550ea777a"},"source":["import speech_recognition as sr \n","from pydub import AudioSegment \n","from pydub.silence import split_on_silence \n","import io  \n","import os \n","r = sr.Recognizer()\n","utku_can = []\n","def audio_to_text(file):\n","    sound = AudioSegment.from_mp3(file)\n","    chunks = split_on_silence(sound,min_silence_len=500,\n","                              silence_thresh=sound.dBFS-14,\n","                              keep_silence=500,\n","    )\n","    \n","    folder_name = \"/content/drive/MyDrive/audio-chunk\"\n","    if not os.path.isdir(folder_name):\n","        os.mkdir(folder_name)\n","    whole_text = \"\"\n","    for i, audio_chunk in enumerate(chunks, start=1):\n","        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n","        audio_chunk.export(chunk_filename, format=\"wav\")\n","        with sr.AudioFile(chunk_filename) as source:\n","            audio_listened = r.record(source)\n","            try:\n","                text = r.recognize_google(audio_listened)\n","            except sr.UnknownValueError as e:\n","                text=\"12.<\"\n","                whole_text += text\n","            else:\n","                text = f\"{text.capitalize()}.< \"\n","                whole_text += text\n","                            \n","    return whole_text\n","\n","\n","\n","\n","\n","\n"," \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Royal armouries.< 12.<\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CbapqCJXplv","executionInfo":{"status":"ok","timestamp":1622983966307,"user_tz":-180,"elapsed":58002,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"8d6cb2b0-571d-4b1d-f09a-61ecad2e569b"},"source":["def audio_to_tr_text(file):\n","    sound = AudioSegment.from_mp3(file)\n","    chunks = split_on_silence(sound,min_silence_len=500,\n","                              silence_thresh=sound.dBFS-14,\n","                              keep_silence=500,\n","    )\n","    \n","    folder_name = \"/content/drive/MyDrive/audio-chunk\"\n","    if not os.path.isdir(folder_name):\n","        os.mkdir(folder_name)\n","    whole_text = \"\"\n","    for i, audio_chunk in enumerate(chunks, start=1):\n","        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n","        audio_chunk.export(chunk_filename, format=\"wav\")\n","        with sr.AudioFile(chunk_filename) as source:\n","            audio_listened = r.record(source)\n","            try:\n","                text = r.recognize_google(audio_listened, language='tr-TR')\n","            except sr.UnknownValueError as e:\n","                text=\"12.<\"\n","                whole_text += text\n","            else:\n","                text = f\"{text.capitalize()}.< \"\n","                whole_text += text\n","                            \n","    return whole_text\n","\n","   \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["O yaramaz olsun portakal seçmeye gelmedim dayı cevap almaya geldim ne hakkında hapis ömer kerem adım asap bozma değil gel güzel güzel konuşalım bizim zamanımız delikanlı adam yapacağını sokak ortasında yapardı kardeş sizin zamandan kimse kalmadı hepsini temizledik ben kaldım ben kaldım yok dayı yanlışımla sen de gittin hikayen kaldı sadece artık çağırınca tıpış tıpış geleceksin anlatacak mısın kardeş yaprağından hafızada zayıfladı birazdan senin burada olduğunu bile unuturum bakarsın ben seni unutacağım adamlardan değilim gözlerimin içine bak ramiz anladın mı nasıl bir adam bilemem kardeş meyveyi soymadan içinden ne çıkacak bilemem sana beri anlatayım.< Bayan arkadaş şeytan zamanında değil mi ömer bugün burada senin canını kurtaran adam senin hayatını kim kurtaracak ramiz çıkacaksın o zaman ne olacak o da güzel hikaye ama erken anlatılırsa tadı kaçar önce tecrübe etmen gerek kardeş.< \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":208},"id":"8AQBjqD0_Dks","executionInfo":{"status":"ok","timestamp":1622985092611,"user_tz":-180,"elapsed":302734,"user":{"displayName":"Utku Can Erdoğan","photoUrl":"","userId":"13503388084803485682"}},"outputId":"5dc6e222-6b53-4423-a80c-725fb47ba090"},"source":["from google.colab import files \n","import moviepy.editor as mp\n","import ipywidgets as widgets\n","from IPython.display import display\n","\n","#@title Otomatik Altyazı Oluşturma Sistemine Hoşgeldiniz...\n","#@markdown ### Lütfen Altyazı Oluşturmak İstediğiniz Seçeneği Seçiniz...\n","Seçim = \"Yabanc\\u0131 Dizi\" #@param [\"Yerli Dizi\",\"Yabancı Dizi\"]\n","#@markdown Lütffen Altyazı Oluşturmak İstediğiniz MP4 Dosyasını Seçiniz...\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('\"{name}\" Dosyası Yüklendi.\\n Çeviriye Başlanıyor...'.format(\n","      name=fn))\n","clip = mp.VideoFileClip(fn)\n","fn=fn[:-1]\n","fn = fn + '3'\n","clip.audio.write_audiofile(fn)\n","clip = str(clip)\n","\n","\n","liste = []  \n","if Seçim == 'Yabanc\\u0131 Dizi' :\n","  for i in range(len_1):\n","   dizi = audio_to_text(fn)\n","   ceviri = dizi.split('<')\n","   len_1 = len(ceviri)\n","   söz = ceviri[i]\n","   söz_1 = translate(input_text=söz)\n","   liste.append(söz_1)\n","\n","if Seçim == 'Yerli Dizi' :\n","  for i in range(len_1):\n","   dizi = audio_to_tr_text(fn)\n","   ceviri = dizi.split('<')\n","   len_1 = len(ceviri)\n","   söz = ceviri[i]\n","   söz_1 = tr_translate(input_text=söz)\n","   liste.append(söz_1)\n","\n","liste_len = len(liste)\n","cevrilmis_cumle = []\n","for i in range(liste_len):\n","  text = liste[i]\n","  text_1 = ' '.join(word for word in text.split()[:-1])\n","  cevrilmis_cumle.append(text_1)\n","cevrilmis_cumle.pop()\n","\n","for i in range(len(cevrilmis_cumle)):\n","  if cevrilmis_cumle[i] == 'okula':\n","    cevrilmis_cumle[i] = ' '\n","  elif cevrilmis_cumle[i] == '':\n","    cevrilmis_cumle[i] = ceviri[i] \n","\n","video_lenght=[]\n","i=1\n","while os.path.exists('/content/drive/MyDrive/audio-chunk'+ fn + '/chunk%s.wav' % i):\n","    with contextlib.closing(wave.open('/content/drive/MyDrive/audio-chunk'+ fn +'/chunk%s.wav' % i, 'r')) as f:\n","        frames = f.getnframes()\n","        rate = f.getframerate()\n","        duration = frames / float(rate)\n","        duration = str(datetime.timedelta(seconds=duration))\n","        video_lenght.append(duration)\n","        i += 1\n","\n","\n","\n","\n","end = []\n","video = []\n","video_len = []\n","date_time = '00:00:00.000'\n","x=0\n","while x<len(video_lenght):\n","    date_time2 = video_lenght[x]\n","    time1 = datetime.datetime.strptime(date_time, '%H:%M:%S.%f')\n","    time2 = datetime.datetime.strptime(date_time2, '%H:%M:%S.%f')\n","    time_zero = datetime.datetime.strptime('00:00:00.000', '%H:%M:%S.%f')\n","    date_time = (time1 - time_zero + time2).time()\n","    date_time = str(date_time)\n","    video.append(date_time)\n","    x += 1\n","\n","begin = ['00:00:00,000']\n","a = 0\n","\n","\n","u=0\n","while u<len(video):\n","  utku = video[u]\n","  utku = utku[:-3]\n","  video_len.append(utku)\n","  u += 1\n","\n","\n","\n","k = 0\n","\n","while k<len(video_len):\n","  rep = video_len[k]\n","  rep = rep.replace('.',',')\n","  end.append(rep)\n","  k+=1\n"," \n","\n","\n","while a<len(end) - 1 :\n","  begin.append(end[a])\n","  a += 1   \n","u=1\n","w=0\n","fn = fn[:-4]\n","while w<len(cevrilmis_cumle):\n","  with open(\"/content/drive/MyDrive/Python/\"+fn+\".srt\", \"a\") as f:\n","    f.write(str(u) + \"\\n\" + begin[w] + \" --> \" + end[w] + \"\\n\" +\n","            cevrilmis_cumle[w] + \"\\n\" + '\\n')\n","    f.close\n","    u += 1\n","    w +=1\n","\n","print(\"İndirme İşlemi Başlatılıyor...\")\n","files.download(\"/content/drive/MyDrive/Python/\"+fn+\".srt\")\n","print(\"İndirme İşlemi Başarılı\\nYine Bekleriz...\")\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-33f51567-71a6-4e2f-8cb4-5724986e6537\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-33f51567-71a6-4e2f-8cb4-5724986e6537\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving underrated funny moments in avatar the last airbender pt 1.mp4 to underrated funny moments in avatar the last airbender pt 1.mp4\n","\"underrated funny moments in avatar the last airbender pt 1.mp4\" Dosyası Yüklendi.\n"," Çeviriye Başlanıyor...\n","[MoviePy] Writing audio in underrated funny moments in avatar the last airbender pt 1.mp3\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7583/7583 [00:09<00:00, 783.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["[MoviePy] Done.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["İndirme İşlemi Başlatılıyor...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_3674f00a-9cf4-4327-8b6c-ea711503bdb4\", \"underrated funny moments in avatar the last airbender pt 1.srt\", 27053)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["İndirme İşlemi Başarılı\n","Yine Bekleriz...\n"],"name":"stdout"}]}]}